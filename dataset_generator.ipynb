{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56aca9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "from utils import create_network_df, generate_od_matrices, prepare_network_data, generate_capacity_matrices\n",
    "from leblanc import leblanc_algorithm\n",
    "from tqdm import tqdm\n",
    "import openmatrix as omx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1ff4cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_sioux = 'data/sioux'\n",
    "filepath_ema = 'data/ema'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3df03539",
   "metadata": {},
   "outputs": [],
   "source": [
    "sioux = create_network_df(network_name=\"SiouxFalls\")\n",
    "T_0_sioux, C_sioux = prepare_network_data(sioux)\n",
    "eps_ema = 0.005\n",
    "ema = create_network_df(network_name=\"EMA\")\n",
    "T_0_ema, C_ema = prepare_network_data(ema)\n",
    "eps_ema = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d02cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading OMX file: ``/home/polina/kans/traffic_assignment/TransportationNetworks/_scripts/demand.omx`` does not exist\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "``/home/polina/kans/traffic_assignment/TransportationNetworks/_scripts/demand.omx`` does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 61\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError reading OMX file: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     59\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m demand_data_ema \u001b[38;5;241m=\u001b[39m \u001b[43mread_omx_demand\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/polina/kans/traffic_assignment/TransportationNetworks/_scripts/demand.omx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m demand_ema \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\n\u001b[1;32m     64\u001b[0m     demand_data_ema[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatrix\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     65\u001b[0m     index\u001b[38;5;241m=\u001b[39mdemand_data_ema[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzones\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     66\u001b[0m     columns\u001b[38;5;241m=\u001b[39mdemand_data_ema[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzones\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     67\u001b[0m )\n\u001b[1;32m     69\u001b[0m OD_eda \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(demand_ema)\n",
      "Cell \u001b[0;32mIn[7], line 29\u001b[0m, in \u001b[0;36mread_omx_demand\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mread_omx_demand\u001b[39m(file_path):\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 29\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43momx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m omx_file:\n\u001b[1;32m     30\u001b[0m             matrix_names \u001b[38;5;241m=\u001b[39m omx_file\u001b[38;5;241m.\u001b[39mlist_matrices()\n\u001b[1;32m     32\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m matrix_names:\n",
      "File \u001b[0;32m~/traffic_assignment/diplom_venv/lib/python3.10/site-packages/openmatrix/__init__.py:53\u001b[0m, in \u001b[0;36mopen_file\u001b[0;34m(filename, mode, title, root_uep, filters, shape, **kwargs)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mopen_file\u001b[39m(filename, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, root_uep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     15\u001b[0m              filters\u001b[38;5;241m=\u001b[39mtables\u001b[38;5;241m.\u001b[39mFilters(complevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fletcher32\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, complib\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzlib\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     16\u001b[0m              shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     17\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03m    Open or create a new OMX file. New files will be created with default\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m    zlib compression enabled.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;124;03m        The file object for reading and writing.\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtitle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mroot_uep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m;\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;66;03m# add omx structure if file is writable\u001b[39;00m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     57\u001b[0m         \u001b[38;5;66;03m# version number\u001b[39;00m\n",
      "File \u001b[0;32m~/traffic_assignment/diplom_venv/lib/python3.10/site-packages/openmatrix/File.py:14\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, f, m, t, r, f1, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, f,m,t,r,f1, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 14\u001b[0m     \u001b[43mtables\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43mf1\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/traffic_assignment/diplom_venv/lib/python3.10/site-packages/tables/file.py:746\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, filename, mode, title, root_uep, filters, **kwargs)\u001b[0m\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams \u001b[38;5;241m=\u001b[39m params\n\u001b[1;32m    745\u001b[0m \u001b[38;5;66;03m# Now, it is time to initialize the File extension\u001b[39;00m\n\u001b[0;32m--> 746\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_g_new\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;66;03m# Check filters and set PyTables format version for new files.\u001b[39;00m\n\u001b[1;32m    749\u001b[0m new \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_v_new\n",
      "File \u001b[0;32m~/traffic_assignment/diplom_venv/lib/python3.10/site-packages/tables/hdf5extension.pyx:396\u001b[0m, in \u001b[0;36mtables.hdf5extension.File._g_new\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/traffic_assignment/diplom_venv/lib/python3.10/site-packages/tables/utils.py:166\u001b[0m, in \u001b[0;36mcheck_file_access\u001b[0;34m(filename, mode)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# The file should be readable.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39maccess(path, os\u001b[38;5;241m.\u001b[39mF_OK):\n\u001b[0;32m--> 166\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m``\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`` does not exist\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39mis_file():\n\u001b[1;32m    168\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIsADirectoryError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m``\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`` is not a regular file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: ``/home/polina/kans/traffic_assignment/TransportationNetworks/_scripts/demand.omx`` does not exist"
     ]
    }
   ],
   "source": [
    "OD_sioux = np.array([\n",
    "    [0, 100, 100, 500, 200, 300, 500, 800, 500, 1300, 500, 200, 500, 300, 500, 500, 400, 100, 300, 300, 100, 400, 300, 100],\n",
    "    [100, 0, 100, 200, 100, 400, 200, 400, 200, 600, 200, 100, 300, 100, 100, 400, 200, 0, 100, 100, 0, 100, 0, 0],\n",
    "    [100, 100, 0, 200, 100, 300, 100, 200, 100, 300, 300, 200, 100, 100, 100, 200, 100, 0, 0, 0, 0, 100, 100, 0],\n",
    "    [500, 200, 200, 0, 500, 400, 400, 700, 700, 1200, 1400, 600, 600, 500, 500, 800, 500, 100, 200, 300, 200, 400, 500, 200],\n",
    "    [200, 100, 100, 500, 0, 200, 200, 500, 800, 1000, 500, 200, 200, 100, 200, 500, 200, 0, 100, 100, 100, 200, 100, 0],\n",
    "    [300, 400, 300, 400, 200, 0, 400, 800, 400, 800, 400, 200, 200, 100, 200, 900, 500, 100, 200, 300, 100, 200, 100, 100],\n",
    "    [500, 200, 100, 400, 200, 400, 0, 1000, 600, 1900, 500, 700, 400, 200, 500, 1400, 1000, 200, 400, 500, 200, 500, 200, 100],\n",
    "    [800, 400, 200, 700, 500, 800, 1000, 0, 800, 1600, 800, 600, 600, 400, 600, 2200, 1400, 300, 700, 900, 400, 500, 300, 200],\n",
    "    [500, 200, 100, 700, 800, 400, 600, 800, 0, 2800, 1400, 600, 600, 600, 900, 1400, 900, 200, 400, 600, 300, 700, 500, 200],\n",
    "    [1300, 600, 300, 1200, 1000, 800, 1900, 1600, 2800, 0, 4000, 2000, 1900, 2100, 4000, 4400, 3900, 700, 1800, 2500, 1200, 2600, 1800, 800],\n",
    "    [500, 200, 300, 1500, 500, 400, 500, 800, 1400, 3900, 0, 1400, 1000, 1600, 1400, 1400, 1000, 100, 400, 600, 400, 1100, 1300, 600],\n",
    "    [200, 100, 200, 600, 200, 200, 700, 600, 600, 2000, 1400, 0, 1300, 700, 700, 700, 600, 200, 300, 400, 300, 700, 700, 500],\n",
    "    [500, 300, 100, 600, 200, 200, 400, 600, 600, 1900, 1000, 1300, 0, 600, 700, 600, 500, 100, 300, 600, 600, 1300, 800, 800],\n",
    "    [300, 100, 100, 500, 100, 100, 200, 400, 600, 2100, 1600, 700, 600, 0, 1300, 700, 700, 100, 300, 500, 400, 1200, 1100, 400],\n",
    "    [500, 100, 100, 500, 200, 200, 500, 600, 1000, 4000, 1400, 700, 700, 1300, 0, 1200, 1500, 200, 800, 1100, 800, 2600, 1000, 400],\n",
    "    [500, 400, 200, 800, 500, 900, 1400, 2200, 1400, 4400, 1400, 700, 600, 700, 1200, 0, 2800, 500, 1300, 1600, 600, 1200, 500, 300],\n",
    "    [400, 200, 100, 500, 200, 500, 1000, 1400, 900, 3900, 1000, 600, 500, 700, 1500, 2800, 0, 600, 1700, 1700, 600, 1700, 600, 300],\n",
    "    [100, 0, 0, 100, 0, 100, 200, 300, 200, 700, 200, 200, 100, 100, 200, 500, 600, 0, 300, 400, 100, 300, 100, 0],\n",
    "    [300, 100, 0, 200, 100, 200, 400, 700, 400, 1800, 400, 300, 300, 300, 800, 1300, 1700, 300, 0, 1200, 400, 1200, 300, 100],\n",
    "    [300, 100, 0, 300, 100, 300, 500, 900, 600, 2500, 600, 500, 600, 500, 1100, 1600, 1700, 400, 1200, 0, 1200, 2400, 700, 400],\n",
    "    [100, 0, 0, 200, 100, 100, 200, 400, 300, 1200, 400, 300, 600, 400, 800, 600, 600, 100, 400, 1200, 0, 1800, 700, 500],\n",
    "    [400, 100, 100, 400, 200, 200, 500, 500, 700, 2600, 1100, 700, 1300, 1200, 2600, 1200, 1700, 300, 1200, 2400, 1800, 0, 2100, 1100],\n",
    "    [300, 0, 100, 500, 100, 100, 200, 300, 500, 1800, 1300, 700, 800, 1100, 1000, 500, 600, 100, 300, 700, 700, 2100, 0, 700],\n",
    "    [100, 0, 0, 200, 0, 100, 100, 200, 200, 800, 600, 500, 700, 400, 400, 300, 300, 0, 100, 400, 500, 1100, 700, 0]\n",
    "])\n",
    "def read_omx_demand(file_path):\n",
    "    try:\n",
    "        with omx.open_file(file_path, 'r') as omx_file:\n",
    "            matrix_names = omx_file.list_matrices()\n",
    "            \n",
    "            if not matrix_names:\n",
    "                raise ValueError(\"No matrices found in OMX file\")\n",
    "            \n",
    "            matrix_name = matrix_names[0]\n",
    "            demand_matrix = omx_file[matrix_name]\n",
    "            \n",
    "            mapping_title = 'NO_TITLE'\n",
    "            if hasattr(omx_file, 'mappings'):\n",
    "                mapping_dict = omx_file.mappings()\n",
    "                if mapping_dict:\n",
    "                    mapping_title = next(iter(mapping_dict.keys()))\n",
    "            \n",
    "            try:\n",
    "                lookup = omx_file.mapping(title=mapping_title)\n",
    "                zones = list(lookup.values())\n",
    "            except:\n",
    "                zones = list(range(1, demand_matrix.shape[0] + 1))\n",
    "                lookup = {zone: idx for idx, zone in enumerate(zones, 1)}\n",
    "            \n",
    "            return {\n",
    "                'matrix': np.array(demand_matrix),\n",
    "                'zones': zones,\n",
    "                'lookup': lookup\n",
    "            }\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error reading OMX file: {e}\")\n",
    "        raise\n",
    "\n",
    "OD_ema = \n",
    "# demand_ema = pd.DataFrame(\n",
    "#     demand_data_ema['matrix'],\n",
    "#     index=demand_data_ema['zones'],\n",
    "#     columns=demand_data_ema['zones']\n",
    "# )\n",
    "\n",
    "# OD_eda = np.array(demand_ema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8a94de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(filepath + '/uncongested', exist_ok=True)\n",
    "os.makedirs(filepath + '/moderate', exist_ok=True)\n",
    "os.makedirs(filepath + '/congested', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7556b45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_matrices=5000\n",
    "uncongested_matrices = generate_od_matrices(D, num_matrices, 'uncongested')\n",
    "capacities = generate_capacity_matrices(C, num_matrices, disruption_level='L')\n",
    "# moderate_matrices = generate_od_matrices(D, num_matrices, 'moderate')\n",
    "# congested_matrices = generate_od_matrices(D, num_matrices, 'congested')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a7da8e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[31mAssertionError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2a5c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_index_file(condition, iters, times, eps, filepath='data/EMA'):\n",
    "    files = os.listdir(filepath + f\"/{condition}\")\n",
    "    indices = [int(f.split('_')[1].split('.')[0]) for f in files if f.startswith('sample_')]\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'condition': condition,\n",
    "        'eps' : eps,\n",
    "        'sample_id': indices,\n",
    "        'iterations' : iters,\n",
    "        'execution_time' : times,\n",
    "        'filename': [filepath + f\"/{condition}/sample_{i:04d}.pkl\" for i in indices]\n",
    "    })\n",
    "    df.to_csv(filepath + f\"/{condition}_index.csv\", index=False)\n",
    "\n",
    "def save_dataset(condition='uncongested', num_samples=5000):\n",
    "    start_time = time.time()\n",
    "    od_matrices = generate_od_matrices(D, num_samples, condition)\n",
    "    capacities = generate_capacity_matrices(C, num_samples, disruption_level='L')\n",
    "    times = []\n",
    "    iters = []\n",
    "    for i in tqdm(range(num_samples), desc=f\"Обработка {condition}\"):\n",
    "        result_matrix, iter_num = leblanc_algorithm(T_0, od_matrices[i], capacities[i], eps)\n",
    "        end_time = time.time()\n",
    "        total_time = end_time - start_time\n",
    "        times.append(total_time)\n",
    "        iters.append(iter_num)\n",
    "        metadata = {\n",
    "            'iterations': iter_num,\n",
    "            'execution_time': total_time,\n",
    "        }\n",
    "        data_pair = {\n",
    "            'input': od_matrices[i],\n",
    "            'output': result_matrix,\n",
    "            'metadata' : metadata\n",
    "        }\n",
    "        \n",
    "        filename = filepath + f\"/{condition}/sample_{i:04d}.pkl\"\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(data_pair, f)\n",
    "\n",
    "    create_index_file(condition, iters, times, eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484e02df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Обработка moderate:   0%|          | 0/1000 [00:00<?, ?it/s]/home/polina/kans/leblanc.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  T = T_0 * (1 + 0.15 * (X / C)**4)\n",
      "/home/polina/kans/leblanc.py:35: RuntimeWarning: divide by zero encountered in divide\n",
      "  C_inv_4 = 1 / C**4\n",
      "Обработка moderate: 100%|██████████| 1000/1000 [29:53<00:00,  1.79s/it]\n"
     ]
    }
   ],
   "source": [
    "save_dataset(condition='moderate', num_samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e35a7ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Обработка congested:  49%|████▊     | 487/1000 [30:08<35:01,  4.10s/it] "
     ]
    }
   ],
   "source": [
    "save_dataset(condition='congested', num_samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5ded39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import aiofiles\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm.asyncio import tqdm_asyncio\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "async def save_sample(condition, i, od_matrix, capacity, eps, filepath):\n",
    "    \"\"\"Async function to process and save a single sample\"\"\"\n",
    "    start_time = time.time()\n",
    "    result_matrix, iter_num = leblanc_algorithm(T_0, od_matrix, capacity, eps)\n",
    "    exec_time = time.time() - start_time\n",
    "    \n",
    "    metadata = {\n",
    "        'iterations': iter_num,\n",
    "        'execution_time': exec_time,\n",
    "    }\n",
    "    data_pair = {\n",
    "        'input': od_matrix,\n",
    "        'output': result_matrix,\n",
    "        'metadata': metadata\n",
    "    }\n",
    "    \n",
    "    filename = f\"{filepath}/{condition}/sample_{i:04d}.pkl\"\n",
    "    async with aiofiles.open(filename, 'wb') as f:\n",
    "        await f.write(pickle.dumps(data_pair))\n",
    "    \n",
    "    return i, iter_num, exec_time\n",
    "\n",
    "async def process_batch(condition, batch_od, batch_c, eps, filepath, start_idx):\n",
    "    \"\"\"Process a batch of samples asynchronously\"\"\"\n",
    "    tasks = [\n",
    "        save_sample(condition, start_idx+i, od, cap, eps, filepath)\n",
    "        for i, (od, cap) in enumerate(zip(batch_od, batch_c))\n",
    "    ]\n",
    "    return await tqdm_asyncio.gather(*tasks, desc=f\"Processing {condition} batch\")\n",
    "\n",
    "async def save_dataset_async(condition='uncongested', num_samples=5000, batch_size=100, eps=0.005, filepath='data/EMA'):\n",
    "    \"\"\"Main async function to generate and save dataset\"\"\"\n",
    "    start_total = time.time()\n",
    "    \n",
    "    # Create directory if not exists\n",
    "    os.makedirs(f\"{filepath}/{condition}\", exist_ok=True)\n",
    "    \n",
    "    # Generate all matrices upfront\n",
    "    od_matrices = generate_od_matrices(D, num_samples, condition)\n",
    "    capacities = generate_capacity_matrices(C, num_samples, disruption_level='L')\n",
    "    \n",
    "    # Process in batches\n",
    "    all_results = []\n",
    "    for batch_start in range(0, num_samples, batch_size):\n",
    "        batch_end = min(batch_start + batch_size, num_samples)\n",
    "        batch_results = await process_batch(\n",
    "            condition,\n",
    "            od_matrices[batch_start:batch_end],\n",
    "            capacities[batch_start:batch_end],\n",
    "            eps,\n",
    "            filepath,\n",
    "            batch_start\n",
    "        )\n",
    "        all_results.extend(batch_results)\n",
    "    \n",
    "    # Prepare and save index file\n",
    "    indices, iters, times = zip(*all_results)\n",
    "    create_index_file(condition, iters, times, eps, filepath)\n",
    "    \n",
    "    print(f\"Total processing time: {time.time() - start_total:.2f} seconds\")\n",
    "\n",
    "def create_index_file(condition, iters, times, eps, filepath='data/EMA'):\n",
    "    \"\"\"Sync function to create index file (unchanged)\"\"\"\n",
    "    df = pd.DataFrame({\n",
    "        'condition': condition,\n",
    "        'eps': eps,\n",
    "        'sample_id': range(len(iters)),\n",
    "        'iterations': iters,\n",
    "        'execution_time': times,\n",
    "        'filename': [f\"{filepath}/{condition}/sample_{i:04d}.pkl\" for i in range(len(iters))]\n",
    "    })\n",
    "    df.to_csv(f\"{filepath}/{condition}_index.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f299deb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available cores: 12\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "print(f\"Available cores: {multiprocessing.cpu_count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a4c8f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "\n",
    "def process_sample(args):\n",
    "    i, od, cap, condition, eps, filepath, T_0 = args\n",
    "    start_time = time.time()\n",
    "    result_matrix, iter_num = leblanc_algorithm(T_0, od, cap, eps)\n",
    "    exec_time = time.time() - start_time\n",
    "    \n",
    "    data = {\n",
    "        'input': od,\n",
    "        'output': result_matrix,\n",
    "        'capacities': cap,\n",
    "        'free_flow_time': T_0,\n",
    "        'metadata': {\n",
    "            'iterations': iter_num,\n",
    "            'execution_time': exec_time\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    with open(f\"{filepath}/{condition}/sample_{i:04d}.pkl\", 'wb') as f:\n",
    "        pickle.dump(data, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    return i, iter_num, exec_time\n",
    "\n",
    "def save_dataset_fast(D, C, T_0, condition='uncongested', num_samples=5000, filepath='data/EMA', eps=0.05):\n",
    "    start_total = time.time()\n",
    "    os.makedirs(f\"{filepath}/{condition}\", exist_ok=True)\n",
    "    \n",
    "    od_matrices = generate_od_matrices(D, num_samples, condition)\n",
    "    capacities = generate_capacity_matrices(C, num_samples, disruption_level='L')\n",
    "    \n",
    "    args = [(i, od_matrices[i], capacities[i], condition, eps, filepath, T_0) for i in range(num_samples)]\n",
    "    \n",
    "    completed = 0\n",
    "    time_per_sample = []\n",
    "    \n",
    "    with ProcessPoolExecutor(max_workers=10) as executor:\n",
    "        futures = {executor.submit(process_sample, arg): i for i, arg in enumerate(args)}\n",
    "        \n",
    "        with tqdm(total=num_samples, desc=\"Processing\") as pbar:\n",
    "            for future in as_completed(futures):\n",
    "                i, iter_num, exec_time = future.result()\n",
    "                time_per_sample.append(exec_time)\n",
    "                completed += 1\n",
    "                \n",
    "                avg_time = np.mean(time_per_sample[-100:]) if len(time_per_sample) > 0 else 0\n",
    "                remaining = (num_samples - completed) * avg_time / 12\n",
    "                \n",
    "                pbar.set_postfix({\n",
    "                    'completed': f\"{completed}/{num_samples}\",\n",
    "                    'avg_time': f\"{avg_time:.2f}s\",\n",
    "                    'remaining': f\"{remaining/60:.1f}min\",\n",
    "                    'total_est': f\"{(time.time() - start_total + remaining)/60:.1f}min\"\n",
    "                })\n",
    "                pbar.update(1)\n",
    "    \n",
    "    results = sorted([future.result() for future in futures], key=lambda x: x[0])\n",
    "    indices, iters, times = zip(*results)\n",
    "    \n",
    "    pd.DataFrame({\n",
    "        'condition': condition,\n",
    "        'eps': eps,\n",
    "        'sample_id': indices,\n",
    "        'iterations': iters,\n",
    "        'execution_time': times,\n",
    "        'filename': [f\"{filepath}/{condition}/sample_{i:04d}.pkl\" for i in indices]\n",
    "    }).to_csv(f\"{filepath}/{condition}_index.csv\", index=False)\n",
    "    \n",
    "    total_time = time.time() - start_total\n",
    "    print(f\"\\nCompleted {num_samples} samples in {total_time/60:.1f} minutes\")\n",
    "    print(f\"Average time per sample: {total_time/num_samples:.2f}s\")\n",
    "    print(f\"Throughput: {num_samples/total_time*60:.1f} samples/minute\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf18a9f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generate_od_matrices' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43msave_dataset_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/sioux_capacities\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.005\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 34\u001b[0m, in \u001b[0;36msave_dataset_fast\u001b[0;34m(condition, num_samples, filepath, eps)\u001b[0m\n\u001b[1;32m     31\u001b[0m start_total \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     32\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcondition\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 34\u001b[0m od_matrices \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_od_matrices\u001b[49m(D, num_samples, condition)\n\u001b[1;32m     35\u001b[0m capacities \u001b[38;5;241m=\u001b[39m generate_capacity_matrices(C, num_samples, disruption_level\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     37\u001b[0m args \u001b[38;5;241m=\u001b[39m [(i, od_matrices[i], capacities[i], condition, eps, filepath) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_samples)]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'generate_od_matrices' is not defined"
     ]
    }
   ],
   "source": [
    "save_dataset_fast(num_samples=5000, filepath='data/sioux_capacities', eps=0.005, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c01fb95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = generate_od_matrices(D, 1)[0], capacities[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32566898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[   0,    0,  707, ...,    0,    0,    0],\n",
       "        [   0,    0, 1323, ...,    0,    0,    0],\n",
       "        [ 297, 1091,    0, ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [   0,    0,    0, ...,    0,    0,    0],\n",
       "        [   0,    0,    0, ...,    0,    0,    0],\n",
       "        [   0,    0,    0, ...,    0,    0,    0]], shape=(74, 74)),\n",
       " 28)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leblanc_algorithm(T_0, x, y, epsilon=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1f0d2d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[   0,    0,  707, ...,    0,    0,    0],\n",
       "        [   0,    0, 1323, ...,    0,    0,    0],\n",
       "        [ 297, 1091,    0, ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [   0,    0,    0, ...,    0,    0,    0],\n",
       "        [   0,    0,    0, ...,    0,    0,    0],\n",
       "        [   0,    0,    0, ...,    0,    0,    0]], shape=(74, 74)),\n",
       " 189)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leblanc_algorithm(T_0, x, y, epsilon=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e36866ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_ema = \"/home/podozerovapo/traffic_assignment/data/EMA/uncongested/sample_0000.pkl\"\n",
    "with open(path_ema, 'rb') as f:\n",
    "    data_ema = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c9ce029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input', 'output', 'metadata'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ema.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c441c11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,  40, 562, ...,   0,   0,   0],\n",
       "       [ 58,   0, 104, ...,   0,   0,   0],\n",
       "       [ 66,  85,   0, ...,   0,   0,   0],\n",
       "       ...,\n",
       "       [  0,   0,   0, ...,   0,   0,   0],\n",
       "       [  0,   0,   0, ...,   0,   0,   0],\n",
       "       [  0,   0,   0, ...,   0,   0,   0]], shape=(74, 74))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ema['input']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diplom_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
